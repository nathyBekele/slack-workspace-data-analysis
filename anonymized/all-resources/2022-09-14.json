[
  {
    "client_msg_id": "29c3385e-cc3b-4578-83a6-d1d0b398116b",
    "type": "message",
    "text": "example gpt-3\n<https://becominghuman.ai/text-generation-using-gpt3-781429c4169>",
    "user": "U03UFV7TUTV",
    "ts": "1663140408.335669",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "P569Y",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "text",
                "text": "example gpt-3\n"
              },
              {
                "type": "link",
                "url": "https://becominghuman.ai/text-generation-using-gpt3-781429c4169",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "g2d3549811da",
      "image_72": "https://secure.gravatar.com/avatar/2d3549811dae404f2ab1ffd6d153680c.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0003-72.png",
      "first_name": "Bryan",
      "real_name": "Bryan Clark",
      "display_name": "Bryan Clark",
      "team": "T03U4J8HMUG",
      "name": "Bryan",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://becominghuman.ai/text-generation-using-gpt3-781429c4169",
        "ts": 1627052876,
        "image_url": "https://miro.medium.com/max/Joanne24/1*nrg70w47ref8jpsjvba-xw.jpeg",
        "image_width": 444,
        "image_height": 250,
        "image_bytes": 104443,
        "service_icon": "https://miro.medium.com/fit/c/152/152/1*shhtyhace2uc3iu0igkwiq.png",
        "id": 1,
        "original_url": "https://becominghuman.ai/text-generation-using-gpt3-781429c4169",
        "fallback": "medium: text generation using gpt3.",
        "text": "hi guys. in this blog, we are going to learn about gpt3 and how it can help us to generate text",
        "title": "text generation using gpt3.",
        "title_link": "https://becominghuman.ai/text-generation-using-gpt3-781429c4169",
        "service_name": "medium",
        "fields": [
          {
            "value": "3 min read",
            "title": "Reading time",
            "short": true
          }
        ],
        "message_blocks": null
      }
    ]
  },
  {
    "client_msg_id": "96b54fe0-1fea-4cbf-a622-788be9f331a2",
    "type": "message",
    "text": "example gpt-2\n<https://www.modeldifferently.com/en/2021/12/generaci%c3%b3n-de-fake-news-con-gpt-2/#3-text-generation-with-gpt-2>",
    "user": "U03UFV7TUTV",
    "ts": "1663140428.409939",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "T1C",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "text",
                "text": "example gpt-2\n"
              },
              {
                "type": "link",
                "url": "https://www.modeldifferently.com/en/2021/12/generaci%c3%b3n-de-fake-news-con-gpt-2/#3-text-generation-with-gpt-2",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "g2d3549811da",
      "image_72": "https://secure.gravatar.com/avatar/2d3549811dae404f2ab1ffd6d153680c.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0003-72.png",
      "first_name": "Bryan",
      "real_name": "Bryan Clark",
      "display_name": "Bryan Clark",
      "team": "T03U4J8HMUG",
      "name": "Bryan",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://www.modeldifferently.com/en/2021/12/generaci%c3%b3n-de-fake-news-con-gpt-2/#3-text-generation-with-gpt-2",
        "ts": 1639094400,
        "image_url": "https://www.modeldifferently.com/modelo_generacion_texto.png",
        "image_width": 512,
        "image_height": 250,
        "image_bytes": 26992,
        "service_icon": "https://www.modeldifferently.com/apple-touch-icon.png",
        "id": 1,
        "original_url": "https://www.modeldifferently.com/en/2021/12/generaci%c3%b3n-de-fake-news-con-gpt-2/#3-text-generation-with-gpt-2",
        "fallback": "model differently: text generation with gpt-2",
        "text": "introduction to text generation models: gpt-2 and use cases.",
        "title": "text generation with gpt-2",
        "title_link": "https://www.modeldifferently.com/en/2021/12/generaci%c3%b3n-de-fake-news-con-gpt-2/#3-text-generation-with-gpt-2",
        "service_name": "model differently",
        "message_blocks": null
      }
    ]
  },
  {
    "client_msg_id": "505761bb-61cd-4d13-a661-a1fb5fdd90e2",
    "type": "message",
    "text": "example opt\n<https://www.pragnakalp.com/exploring-the-text-generation-with-opt-open-pre-trained-transformers/>",
    "user": "U03UFV7TUTV",
    "ts": "1663140470.635409",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "k0=z",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "text",
                "text": "example opt\n"
              },
              {
                "type": "link",
                "url": "https://www.pragnakalp.com/exploring-the-text-generation-with-opt-open-pre-trained-transformers/",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "g2d3549811da",
      "image_72": "https://secure.gravatar.com/avatar/2d3549811dae404f2ab1ffd6d153680c.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0003-72.png",
      "first_name": "Bryan",
      "real_name": "Bryan Clark",
      "display_name": "Bryan Clark",
      "team": "T03U4J8HMUG",
      "name": "Bryan",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://www.pragnakalp.com/exploring-the-text-generation-with-opt-open-pre-trained-transformers/",
        "ts": 1655539239,
        "image_url": "https://www.pragnakalp.com/wp-content/uploads/2022/06/exploring-the-text-generation-with-opt.jpg",
        "image_width": 477,
        "image_height": 250,
        "image_bytes": 278229,
        "service_icon": "https://www.pragnakalp.com/wp-content/uploads/2022/05/cropped-pk-color-512-180x180.png",
        "id": 1,
        "original_url": "https://www.pragnakalp.com/exploring-the-text-generation-with-opt-open-pre-trained-transformers/",
        "fallback": "pragnakalp techlabs: ai nlp chatbot development company from india: exploring the text generation with opt (open pre-trained transformers)",
        "text": "introduction facebook/meta ai has introduced a new large language model trained on billions of parameters called opt (open pre-trained transformers), ranging from 125m to 175b parameters. it can be used to generate creative text, solve simple math problems, answer reading comprehension questions, and address other natural language processing related issues. we tried a few different \u2026 continue reading exploring the text generation with opt (open pre-trained transformers)",
        "title": "exploring the text generation with opt (open pre-trained transformers)",
        "title_link": "https://www.pragnakalp.com/exploring-the-text-generation-with-opt-open-pre-trained-transformers/",
        "service_name": "pragnakalp techlabs: ai nlp chatbot development company from india",
        "fields": [
          {
            "value": "Pragnakalp Techlabs",
            "title": "Written by",
            "short": true
          },
          {
            "value": "6 minutes",
            "title": "Est. reading time",
            "short": true
          }
        ],
        "message_blocks": null
      }
    ]
  },
  {
    "client_msg_id": "8d2ed41d-6329-49c2-961d-3312964bf42d",
    "type": "message",
    "text": "<https://datascience.stackexchange.com/questions/5Joanne65/what-is-the-positional-encoding-in-the-transformer-model>",
    "user": "U03UG32J3PC",
    "ts": "1663140927.779899",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "v9VBK",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://datascience.stackexchange.com/questions/5Joanne65/what-is-the-positional-encoding-in-the-transformer-model",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "g9e7487b036e",
      "image_72": "https://secure.gravatar.com/avatar/9e7487b036ed726d016a0c5d8189773c.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0005-72.png",
      "first_name": "Zachary",
      "real_name": "Zachary Clark",
      "display_name": "Zachary Clark",
      "team": "T03U4J8HMUG",
      "name": "Zachary",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://datascience.stackexchange.com/questions/5Joanne65/what-is-the-positional-encoding-in-the-transformer-model",
        "thumb_url": "https://cdn.sstatic.net/sites/datascience/img/apple-touch-icon@2.png?v=04de5a808425",
        "thumb_width": 316,
        "thumb_height": 316,
        "service_icon": "https://cdn.sstatic.net/sites/datascience/img/apple-touch-icon.png?v=5e1a482deef9",
        "id": 1,
        "original_url": "https://datascience.stackexchange.com/questions/5Joanne65/what-is-the-positional-encoding-in-the-transformer-model",
        "fallback": "data science stack exchange: what is the positional encoding in the transformer model?",
        "text": "i'm trying to read and understand the paper attention is all you need and in it, there is a picture: i don't know what positional encoding is. by listening to some youtube videos i've found out th...",
        "title": "what is the positional encoding in the transformer model?",
        "title_link": "https://datascience.stackexchange.com/questions/5Joanne65/what-is-the-positional-encoding-in-the-transformer-model",
        "service_name": "data science stack exchange",
        "message_blocks": null
      }
    ]
  },
  {
    "client_msg_id": "f0534f30-188a-47ef-8bac-4a32e8910c03",
    "type": "message",
    "text": "<https://360digitmg.com/gpt-vs-bert>",
    "user": "U03UJGRN5E0",
    "ts": "1663153963.176449",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "cHiG",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://360digitmg.com/gpt-vs-bert",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "35b05758f532",
      "image_72": "https://avatars.slack-edge.com/2022-09-30/4156429070997_35b05758f532bdef5b5f_72.jpg",
      "first_name": "Dennis",
      "real_name": "Dennis Parker",
      "display_name": "Dennis Parker",
      "team": "T03U4J8HMUG",
      "name": "Dennis",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://360digitmg.com/gpt-vs-bert",
        "image_url": "https://360digit.b-cdn.net/uploads/blog/351.png",
        "image_width": 360,
        "image_height": 240,
        "image_bytes": 14205,
        "service_icon": "https://360digitmg.com/assets/img/favicon.png",
        "id": 1,
        "original_url": "https://360digitmg.com/gpt-vs-bert",
        "fallback": "360digitmg.com: gpt vs bert in artificial intelligence- 360digitmg",
        "text": "gpt (generative pre-trained transformer), bert (bidirectional encoder representations from transformers) is credited as one of the earliest pre-trained algorithms to perform natural language processing (nlp) tasks.",
        "title": "gpt vs bert in artificial intelligence- 360digitmg",
        "title_link": "https://360digitmg.com/gpt-vs-bert",
        "service_name": "360digitmg.com",
        "message_blocks": null
      }
    ]
  },
  {
    "client_msg_id": "c42861c8-d7fd-4376-a0b6-a9c2ee211238",
    "type": "message",
    "text": "<https://docs.cohere.ai/text-classification-embeddings/?utm_campaign=onboarding&amp;utm_medium=email&amp;utm_source=intercom>",
    "user": "U03UFV7HFNF",
    "ts": "1663157373.128589",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "WSzra",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://docs.cohere.ai/text-classification-embeddings/?utm_campaign=onboarding&utm_medium=email&utm_source=intercom",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "3166d51d23f1",
      "image_72": "https://avatars.slack-edge.com/2022-08-20/3991799522480_3166d51d23f1da2374e9_72.jpg",
      "first_name": "Glenn",
      "real_name": "Glenn Richardson",
      "display_name": "Glenn Richardson",
      "team": "T03U4J8HMUG",
      "name": "Glenn",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://docs.cohere.ai/text-classification-embeddings/?utm_campaign=onboarding&utm_medium=email&utm_source=intercom",
        "image_url": "https://docs.cohere.ai/img/share-img.png",
        "image_width": 476,
        "image_height": 250,
        "image_bytes": 10474,
        "service_icon": "https://docs.cohere.ai/img/apple-touch-icon.png",
        "id": 1,
        "original_url": "https://docs.cohere.ai/text-classification-embeddings/?utm_campaign=onboarding&amp;utm_medium=email&amp;utm_source=intercom",
        "fallback": "cohere api docs: api documentation | cohere ai",
        "text": "use the api to generate completions, distill text into semantically meaningful vectors, and more. get state-of-the-art natural language processing without the need for expensive supercomputing infrastructure.",
        "title": "api documentation | cohere ai",
        "title_link": "https://docs.cohere.ai/text-classification-embeddings/?utm_campaign=onboarding&utm_medium=email&utm_source=intercom",
        "service_name": "cohere api docs",
        "message_blocks": null
      }
    ]
  },
  {
    "client_msg_id": "62b1bed8-d5e6-4276-88f9-6bc261ee6dc9",
    "type": "message",
    "text": "<https://stackabuse.com/transformer-token-and-position-embedding-with-keras/>",
    "user": "U03V5Q9N516",
    "ts": "1663157887.860779",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "Kqdex",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://stackabuse.com/transformer-token-and-position-embedding-with-keras/",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "g164928c3a69",
      "image_72": "https://secure.gravatar.com/avatar/164928c3a69af29d42a5e90b928e2f71.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0010-72.png",
      "first_name": "Steven",
      "real_name": "Steven Haas",
      "display_name": "Steven Haas",
      "team": "T03U4J8HMUG",
      "name": "Steven",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://stackabuse.com/transformer-token-and-position-embedding-with-keras/",
        "ts": 1659349800,
        "service_icon": "https://stackabuse.com/assets/images/favicon.ico",
        "id": 1,
        "original_url": "https://stackabuse.com/transformer-token-and-position-embedding-with-keras/",
        "fallback": "stack abuse: transformer token and position embedding with keras",
        "text": "there are plenty of guides explaining how transformers work, and for building an intuition on a key element of them - token and position embedding. positional...",
        "title": "transformer token and position embedding with keras",
        "title_link": "https://stackabuse.com/transformer-token-and-position-embedding-with-keras/",
        "service_name": "stack abuse",
        "fields": [
          {
            "value": "David Landup",
            "title": "Written by",
            "short": true
          },
          {
            "value": "python, machine learning, tensorflow, nlp, keras, deep learning",
            "title": "Filed under",
            "short": true
          }
        ],
        "message_blocks": null
      }
    ]
  },
  {
    "client_msg_id": "f2e017bf-129f-4f01-a89a-26117037e872",
    "type": "message",
    "text": "<https://www.youtube.com/watch?v=-qh8frhqfhm&amp;t=185s>",
    "user": "U03UD68RQH3",
    "ts": "1663158373.813019",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "aHuP",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://www.youtube.com/watch?v=-qh8frhqfhm&t=185s",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "20cf1bb98890",
      "image_72": "https://avatars.slack-edge.com/2022-09-19/4112933864561_20cf1bb98890146c716f_72.png",
      "first_name": "James",
      "real_name": "James Mann",
      "display_name": "James Mann",
      "team": "T03U4J8HMUG",
      "name": "James",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://www.youtube.com/watch?v=-qh8frhqfhm&amp;t=185s",
        "thumb_url": "https://i.ytimg.com/vi/-qh8frhqfhm/hqdefault.jpg",
        "thumb_width": 480,
        "thumb_height": 360,
        "video_html": "<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/-qh8frhqfhm?feature=oembed&start=185&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"the narrated transformer language model\"></iframe>",
        "video_html_width": 400,
        "video_html_height": 225,
        "service_icon": "https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png",
        "id": 1,
        "original_url": "https://www.youtube.com/watch?v=-qh8frhqfhm&amp;t=185s",
        "fallback": "youtube video: the narrated transformer language model",
        "title": "the narrated transformer language model",
        "title_link": "https://www.youtube.com/watch?v=-qh8frhqfhm&amp;t=185s",
        "author_name": "jay alammar",
        "author_link": "https://www.youtube.com/channel/ucmowsohty5prme-3qhubfpq",
        "service_name": "youtube",
        "service_url": "https://www.youtube.com/",
        "message_blocks": null
      }
    ],
    "reactions": [
      {
        "name": "+1",
        "users": [
          "U03UG4Q7V42",
          "U03UG1Z21JP"
        ],
        "count": 2
      }
    ]
  },
  {
    "client_msg_id": "85118bba-d713-4a86-b9b8-5de1d9734605",
    "type": "message",
    "text": "<https://Michelle.com/cohere-ai/notebooks>",
    "user": "U03UUR571A5",
    "ts": "1663158918.298649",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "TZoH",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://Michelle.com/cohere-ai/notebooks",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "g95c5cde44bc",
      "image_72": "https://secure.gravatar.com/avatar/95c5cde44bc023bd369920b7e1ed0c94.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0017-72.png",
      "first_name": "Kelsey",
      "real_name": "Kelsey Shields",
      "display_name": "Kelsey Shields",
      "team": "T03U4J8HMUG",
      "name": "Kelsey",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "id": 1,
        "color": "24292f",
        "bot_id": "b03uyh1bwqz",
        "app_unfurl_url": "https://Michelle.com/cohere-ai/notebooks",
        "is_app_unfurl": true,
        "app_id": "a01bp7r4kny",
        "fallback": "cohere-ai/notebooks",
        "text": "code examples and jupyter notebooks for the cohere platform",
        "title": "cohere-ai/notebooks",
        "fields": [
          {
            "value": "51",
            "title": "Stars",
            "short": true
          },
          {
            "value": "Jupyter Notebook",
            "title": "Language",
            "short": true
          }
        ],
        "message_blocks": null
      }
    ],
    "reactions": [
      {
        "name": "+1",
        "users": [
          "U03UJN29Y4C",
          "U03UFV7HFNF"
        ],
        "count": 2
      }
    ]
  },
  {
    "type": "message",
    "text": "",
    "user": "U03UJH1EQQL",
    "ts": "1663159039.991459",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "caU",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": []
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "81b299d9869c",
      "image_72": "https://avatars.slack-edge.com/2022-08-20/3953555815671_81b299d9869ca44e70c1_72.png",
      "first_name": "Mason",
      "real_name": "Mason Harrington",
      "display_name": "Mason Harrington",
      "team": "T03U4J8HMUG",
      "name": "Mason",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "id": 1,
        "color": "d0d0d0",
        "bot_id": "b03uyh1bwqz",
        "app_unfurl_url": "https://Michelle.com/cohere-ai/notebooks",
        "is_app_unfurl": true,
        "app_id": "a01bp7r4kny",
        "from_url": "https://Joanneacademybatch6.slack.com/archives/c03t89pmjkg/p1663158918298649",
        "is_share": true,
        "fallback": "cohere-ai/notebooks",
        "text": "code examples and jupyter notebooks for the cohere platform",
        "title": "cohere-ai/notebooks",
        "fields": [
          {
            "value": "51",
            "title": "Stars",
            "short": true
          },
          {
            "value": "Jupyter Notebook",
            "title": "Language",
            "short": true
          }
        ],
        "message_blocks": null
      }
    ]
  },
  {
    "client_msg_id": "206cc06d-33f6-4037-a560-5ce8c7a5874d",
    "type": "message",
    "text": "an end to end guide on how to configure the dvc along with the gcp \n<https://iterative.ai/blog/using-gcp-remotes-in-dvc|https://iterative.ai/blog/using-gcp-remotes-in-dvc>",
    "user": "U03UG0YHAUT",
    "ts": "1663159553.224039",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "23Y",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "text",
                "text": "an end to end guide on how to configure the dvc along with the gcp \n"
              },
              {
                "type": "link",
                "url": "https://iterative.ai/blog/using-gcp-remotes-in-dvc",
                "text": "https://iterative.ai/blog/using-gcp-remotes-in-dvc"
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "e7b0c8269999",
      "image_72": "https://avatars.slack-edge.com/2022-09-20/4099393715542_e7b0c82699998d3b3ade_72.jpg",
      "first_name": "David",
      "real_name": "David Nguyen",
      "display_name": "David Nguyen",
      "team": "T03U4J8HMUG",
      "name": "David",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://iterative.ai/blog/using-gcp-remotes-in-dvc",
        "ts": 1657054800,
        "image_url": "https://iterative.ai/blog/images/2022-07-06/dvc-gcp.png",
        "image_width": 476,
        "image_height": 250,
        "image_bytes": 363289,
        "service_icon": "https://iterative.ai/apple-touch-icon-48x48.png?v=78541f5bcb19bcbcdc375b47b7bf2b5a",
        "id": 1,
        "original_url": "https://iterative.ai/blog/using-gcp-remotes-in-dvc",
        "fallback": "developer tools for machine learning | iterative: syncing data to gcp storage buckets",
        "text": "we're going to set up an gcp storage bucket remote in a dvc project.",
        "title": "syncing data to gcp storage buckets",
        "title_link": "https://iterative.ai/blog/using-gcp-remotes-in-dvc",
        "service_name": "developer tools for machine learning | iterative",
        "message_blocks": null
      }
    ]
  },
  {
    "client_msg_id": "60b09686-6038-4b9c-86cf-9590011249e0",
    "type": "message",
    "text": "<https://docs.Michelle.com/en/actions/hosting-your-own-runners/about-self-hosted-runners>",
    "user": "U03UUR571A5",
    "ts": "1663162240.094629",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "Rs1",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://docs.Michelle.com/en/actions/hosting-your-own-runners/about-self-hosted-runners",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "g95c5cde44bc",
      "image_72": "https://secure.gravatar.com/avatar/95c5cde44bc023bd369920b7e1ed0c94.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0017-72.png",
      "first_name": "Kelsey",
      "real_name": "Kelsey Shields",
      "display_name": "Kelsey Shields",
      "team": "T03U4J8HMUG",
      "name": "Kelsey",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": null
  },
  {
    "client_msg_id": "2dfbbde8-0e66-4dcc-9404-97d3a466d85a",
    "type": "message",
    "text": "<https://d2l.ai/chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html>",
    "user": "U03U1FNPEUX",
    "ts": "1663164351.324459",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "29rD",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://d2l.ai/chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "37a12a7dbb92",
      "image_72": "https://avatars.slack-edge.com/2022-09-09/4058043481011_37a12a7dbb926b2c9c86_72.png",
      "first_name": "Jennifer",
      "real_name": "Jennifer Carrillo",
      "display_name": "Jennifer Carrillo",
      "team": "T03U4J8HMUG",
      "name": "Jennifer",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "reactions": [
      {
        "name": "+1",
        "users": [
          "U03V6HMRPGQ"
        ],
        "count": 1
      }
    ],
    "attachments": null
  },
  {
    "client_msg_id": "e9c02e80-08a7-4418-aabc-8fca2b08d903",
    "type": "message",
    "text": "<https://medium.com/sfu-cspmp/nlp-word-embedding-techniques-for-text-analysis-ec4e91bb886f>",
    "user": "U03U1FNPEUX",
    "ts": "1663164787.541409",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "aBQN",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://medium.com/sfu-cspmp/nlp-word-embedding-techniques-for-text-analysis-ec4e91bb886f",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "37a12a7dbb92",
      "image_72": "https://avatars.slack-edge.com/2022-09-09/4058043481011_37a12a7dbb926b2c9c86_72.png",
      "first_name": "Jennifer",
      "real_name": "Jennifer Carrillo",
      "display_name": "Jennifer Carrillo",
      "team": "T03U4J8HMUG",
      "name": "Jennifer",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://medium.com/sfu-cspmp/nlp-word-embedding-techniques-for-text-analysis-ec4e91bb886f",
        "ts": 1580804495,
        "image_url": "https://miro.medium.com/max/1200/1*gze94vgd3pktwrdmzlpdxa.png",
        "image_width": 521,
        "image_height": 250,
        "image_bytes": 157199,
        "service_icon": "https://miro.medium.com/fit/c/152/152/1*shhtyhace2uc3iu0igkwiq.png",
        "id": 1,
        "original_url": "https://medium.com/sfu-cspmp/nlp-word-embedding-techniques-for-text-analysis-ec4e91bb886f",
        "fallback": "medium: nlp: word embedding techniques for text analysis",
        "text": "fangyu gu, srijeev sarkar, yizhou sun, hengzhi wu, kacy wu",
        "title": "nlp: word embedding techniques for text analysis",
        "title_link": "https://medium.com/sfu-cspmp/nlp-word-embedding-techniques-for-text-analysis-ec4e91bb886f",
        "service_name": "medium",
        "fields": [
          {
            "value": "15 min read",
            "title": "Reading time",
            "short": true
          }
        ],
        "message_blocks": null
      }
    ]
  },
  {
    "client_msg_id": "b6aa9b45-d2ae-4f8c-b69f-52ef6cf97ae6",
    "type": "message",
    "text": "<https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/>",
    "user": "U03UG32J3PC",
    "ts": "1663165975.522889",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "emAQ",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "g9e7487b036e",
      "image_72": "https://secure.gravatar.com/avatar/9e7487b036ed726d016a0c5d8189773c.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0005-72.png",
      "first_name": "Zachary",
      "real_name": "Zachary Clark",
      "display_name": "Zachary Clark",
      "team": "T03U4J8HMUG",
      "name": "Zachary",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/",
        "ts": 1574219184,
        "thumb_url": "https://cdn.analyticsvidhya.com/wp-content/uploads/2019/11/attention_deep_learning.jpg",
        "thumb_width": 1024,
        "thumb_height": 576,
        "service_icon": "https://www.analyticsvidhya.com/wp-content/uploads/2015/02/logo_square_v2.jpg",
        "id": 1,
        "original_url": "https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/",
        "fallback": "analytics vidhya: attention mechanism in deep learning | attention model keras",
        "text": "a complete guide to attention models and attention mechanisms in deep learning. learn how to implement an attention model in python using keras.",
        "title": "attention mechanism in deep learning | attention model keras",
        "title_link": "https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/",
        "service_name": "analytics vidhya",
        "fields": [
          {
            "value": "american_express",
            "title": "Written by",
            "short": true
          },
          {
            "value": "27 minutes",
            "title": "Est. reading time",
            "short": true
          }
        ],
        "message_blocks": null
      }
    ],
    "reactions": [
      {
        "name": "heart",
        "users": [
          "U03V6HMRPGQ"
        ],
        "count": 1
      }
    ]
  },
  {
    "client_msg_id": "1103fbde-b168-45ac-9eac-865d4b84161c",
    "type": "message",
    "text": "<https://www.geeksforgeeks.org/python-word-embedding-using-word2vec/>",
    "user": "U03UG0SFHGT",
    "ts": "1663166041.069929",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "mi1p",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://www.geeksforgeeks.org/python-word-embedding-using-word2vec/",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "60e1cb8a7a1b",
      "image_72": "https://avatars.slack-edge.com/2022-08-20/3953568416743_60e1cb8a7a1b6c71c2bb_72.jpg",
      "first_name": "Robert",
      "real_name": "Robert James",
      "display_name": "Robert James",
      "team": "T03U4J8HMUG",
      "name": "Robert",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://www.geeksforgeeks.org/python-word-embedding-using-word2vec/",
        "ts": 1526667345,
        "thumb_url": "https://media.geeksforgeeks.org/wp-content/cdn-uploads/gfg_200x200-min.png",
        "thumb_width": 200,
        "thumb_height": 200,
        "service_icon": "https://www.geeksforgeeks.org/wp-content/uploads/gfg_200x200.png",
        "id": 1,
        "original_url": "https://www.geeksforgeeks.org/python-word-embedding-using-word2vec/",
        "fallback": "geeksforgeeks: python | word embedding using word2vec - geeksforgeeks",
        "text": "a computer science portal for geeks. it contains well written, well thought and well explained computer science and programming articles, quizzes and practice/competitive programming/company interview questions.",
        "title": "python | word embedding using word2vec - geeksforgeeks",
        "title_link": "https://www.geeksforgeeks.org/python-word-embedding-using-word2vec/",
        "service_name": "geeksforgeeks",
        "message_blocks": null
      }
    ]
  },
  {
    "client_msg_id": "0105b798-9674-4c3e-ad9f-ec35cf0ba1eb",
    "type": "message",
    "text": "<https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/#:~:text=positional%20encoding%20describes%20the%20location,item's%20position%20in%20transformer%20models>.",
    "user": "U03V6HMRPGQ",
    "ts": "1663168108.407519",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "+Et2",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/#:~:text=positional%20encoding%20describes%20the%20location,item's%20position%20in%20transformer%20models",
                "text": null
              },
              {
                "type": "text",
                "text": "."
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "23fcf5329c03",
      "image_72": "https://avatars.slack-edge.com/2022-08-22/3969139924917_23fcf5329c03131c761f_72.png",
      "first_name": "Lisa",
      "real_name": "Lisa Dickerson",
      "display_name": "Lisa Dickerson",
      "team": "T03U4J8HMUG",
      "name": "Lisa",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": null
  },
  {
    "client_msg_id": "7f93acdb-6286-4b84-910c-9adbe1216957",
    "type": "message",
    "text": "<https://www.youtube.com/watch?v=dichicuzfow>",
    "user": "U03UJGRN5E0",
    "ts": "1663171674.935039",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "4rrMh",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://www.youtube.com/watch?v=dichicuzfow",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "35b05758f532",
      "image_72": "https://avatars.slack-edge.com/2022-09-30/4156429070997_35b05758f532bdef5b5f_72.jpg",
      "first_name": "Dennis",
      "real_name": "Dennis Parker",
      "display_name": "Dennis Parker",
      "team": "T03U4J8HMUG",
      "name": "Dennis",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://www.youtube.com/watch?v=dichicuzfow",
        "thumb_url": "https://i.ytimg.com/vi/dichicuzfow/hqdefault.jpg",
        "thumb_width": 480,
        "thumb_height": 360,
        "video_html": "<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/dichicuzfow?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"visual guide to transformer neural networks - (episode 1) position embeddings\"></iframe>",
        "video_html_width": 400,
        "video_html_height": 225,
        "service_icon": "https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png",
        "id": 1,
        "original_url": "https://www.youtube.com/watch?v=dichicuzfow",
        "fallback": "youtube video: visual guide to transformer neural networks - (episode 1) position embeddings",
        "title": "visual guide to transformer neural networks - (episode 1) position embeddings",
        "title_link": "https://www.youtube.com/watch?v=dichicuzfow",
        "author_name": "hedu ai",
        "author_link": "https://www.youtube.com/c/hedumathematicsofintelligence",
        "service_name": "youtube",
        "service_url": "https://www.youtube.com/",
        "message_blocks": null
      }
    ]
  },
  {
    "client_msg_id": "f1e52bec-7dc3-4dd3-8b10-4c5cf248669f",
    "type": "message",
    "text": "<https://www.csie.ntu.edu.tw/~yvchen/doc/emnlp20_positionvec.pdf>",
    "user": "U03UG5VFN03",
    "ts": "1663171779.718079",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "Oqes",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://www.csie.ntu.edu.tw/~yvchen/doc/emnlp20_positionvec.pdf",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "1eec51b41e1b",
      "image_72": "https://avatars.slack-edge.com/2022-08-20/3980936144801_1eec51b41e1b370500be_72.png",
      "first_name": "Susan",
      "real_name": "Susan Lewis",
      "display_name": "Susan Lewis",
      "team": "T03U4J8HMUG",
      "name": "Susan",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": null
  },
  {
    "client_msg_id": "b52ac76d-660c-4c0d-a489-326ac3e746c6",
    "type": "message",
    "text": "<https://aclanthology.org/2021.emnlp-main.266.pdf>",
    "user": "U03UG5VFN03",
    "ts": "1663171780.760459",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "7IB",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://aclanthology.org/2021.emnlp-main.266.pdf",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "1eec51b41e1b",
      "image_72": "https://avatars.slack-edge.com/2022-08-20/3980936144801_1eec51b41e1b370500be_72.png",
      "first_name": "Susan",
      "real_name": "Susan Lewis",
      "display_name": "Susan Lewis",
      "team": "T03U4J8HMUG",
      "name": "Susan",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": null
  },
  {
    "client_msg_id": "1595e4b9-a3ae-479c-b632-610ff79992ad",
    "type": "message",
    "text": "<https://www.kdnuggets.com/2021/01/attention-mechanism-deep-learning-explained.html>",
    "user": "U03UG5VFN03",
    "ts": "1663171899.617779",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "6nn",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://www.kdnuggets.com/2021/01/attention-mechanism-deep-learning-explained.html",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "1eec51b41e1b",
      "image_72": "https://avatars.slack-edge.com/2022-08-20/3980936144801_1eec51b41e1b370500be_72.png",
      "first_name": "Susan",
      "real_name": "Susan Lewis",
      "display_name": "Susan Lewis",
      "team": "T03U4J8HMUG",
      "name": "Susan",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://www.kdnuggets.com/2021/01/attention-mechanism-deep-learning-explained.html",
        "thumb_url": "https://www.kdnuggets.com/wp-content/uploads/fig1-chauhan-attention-mechanism-deep-learning-explained.jpg",
        "thumb_width": 870,
        "thumb_height": 614,
        "service_icon": "https://www.kdnuggets.com/wp-content/themes/kdn17/images/favicon.ico",
        "id": 1,
        "original_url": "https://www.kdnuggets.com/2021/01/attention-mechanism-deep-learning-explained.html",
        "fallback": "kdnuggets: attention mechanism in deep learning, explained - kdnuggets",
        "text": "attention is a powerful mechanism developed to enhance the performance of the encoder-decoder architecture on neural network-based machine translation tasks. learn more about how this process works and how to implement the approach into your work.",
        "title": "attention mechanism in deep learning, explained - kdnuggets",
        "title_link": "https://www.kdnuggets.com/2021/01/attention-mechanism-deep-learning-explained.html",
        "service_name": "kdnuggets",
        "message_blocks": null
      }
    ]
  },
  {
    "client_msg_id": "ba6edf88-09cc-48dc-9986-01317cc115ec",
    "type": "message",
    "text": "<https://medium.com/@angelina.yang/whats-the-difference-between-attention-and-self-attention-in-transformer-models-2846665880b6>",
    "user": "U03V6HMRPGQ",
    "ts": "1663173497.056239",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "jOr+",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://medium.com/@angelina.yang/whats-the-difference-between-attention-and-self-attention-in-transformer-models-2846665880b6",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "23fcf5329c03",
      "image_72": "https://avatars.slack-edge.com/2022-08-22/3969139924917_23fcf5329c03131c761f_72.png",
      "first_name": "Lisa",
      "real_name": "Lisa Dickerson",
      "display_name": "Lisa Dickerson",
      "team": "T03U4J8HMUG",
      "name": "Lisa",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://medium.com/@angelina.yang/whats-the-difference-between-attention-and-self-attention-in-transformer-models-2846665880b6",
        "ts": 1658265482,
        "image_url": "https://miro.medium.com/max/1200/0*xlotiwu-mcwmipzw.jpeg",
        "image_width": 255,
        "image_height": 250,
        "image_bytes": 128858,
        "service_icon": "https://miro.medium.com/fit/c/152/152/1*shhtyhace2uc3iu0igkwiq.png",
        "id": 1,
        "original_url": "https://medium.com/@angelina.yang/whats-the-difference-between-attention-and-self-attention-in-transformer-models-2846665880b6",
        "fallback": "medium: what\u2019s the difference between attention and self-attention in transformer models?",
        "text": "\u201cattention\u201d is one of the key ideas in the transformer architecture. there are a lot of deep explanations elsewhere so here we\u2019d like to\u2026",
        "title": "what\u2019s the difference between attention and self-attention in transformer models?",
        "title_link": "https://medium.com/@angelina.yang/whats-the-difference-between-attention-and-self-attention-in-transformer-models-2846665880b6",
        "service_name": "medium",
        "fields": [
          {
            "value": "2 min read",
            "title": "Reading time",
            "short": true
          }
        ],
        "message_blocks": null
      }
    ]
  },
  {
    "client_msg_id": "278e05ad-ee91-4d5c-8248-62d64bc92e8e",
    "type": "message",
    "text": "<https://theaisummer.com/attention/>",
    "user": "U03V6HMRPGQ",
    "ts": "1663173958.893259",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "rBYB",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://theaisummer.com/attention/",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "23fcf5329c03",
      "image_72": "https://avatars.slack-edge.com/2022-08-22/3969139924917_23fcf5329c03131c761f_72.png",
      "first_name": "Lisa",
      "real_name": "Lisa Dickerson",
      "display_name": "Lisa Dickerson",
      "team": "T03U4J8HMUG",
      "name": "Lisa",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://theaisummer.com/attention/",
        "ts": 1605733200,
        "image_url": "https://theaisummer.com/static/e9145585ddeed479c482761fe069518d/ee604/attention.png",
        "image_width": 493,
        "image_height": 250,
        "image_bytes": 29658,
        "service_icon": "https://theaisummer.com/static/b45b24c62e57511ad6ca9e436893489f/apple-icon-57x57.png",
        "id": 1,
        "original_url": "https://theaisummer.com/attention/",
        "fallback": "ai summer: how attention works in deep learning: understanding the attention mechanism in sequence models | ai summer",
        "text": "new to natural language processing? this is the ultimate beginner\u2019s guide to the attention mechanism and sequence learning to get you started",
        "title": "how attention works in deep learning: understanding the attention mechanism in sequence models | ai summer",
        "title_link": "https://theaisummer.com/attention/",
        "service_name": "ai summer",
        "message_blocks": null
      }
    ]
  },
  {
    "client_msg_id": "31eaabd7-bd14-4f29-a366-5ed193d346f8",
    "type": "message",
    "text": "<https://blogs.nvidia.com/blog/2022/03/25/what-is-a-transformer-model/>",
    "user": "U03UG5VFN03",
    "ts": "1663176408.515859",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "V6V",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://blogs.nvidia.com/blog/2022/03/25/what-is-a-transformer-model/",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "1eec51b41e1b",
      "image_72": "https://avatars.slack-edge.com/2022-08-20/3980936144801_1eec51b41e1b370500be_72.png",
      "first_name": "Susan",
      "real_name": "Susan Lewis",
      "display_name": "Susan Lewis",
      "team": "T03U4J8HMUG",
      "name": "Susan",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://blogs.nvidia.com/blog/2022/03/25/what-is-a-transformer-model/",
        "ts": 1648213107,
        "image_url": "https://blogs.nvidia.com/wp-content/uploads/2022/03/transformer-model-kv-x1280-final.jpg",
        "image_width": 469,
        "image_height": 250,
        "image_bytes": 50152,
        "service_icon": "https://blogs.nvidia.com/favicon.ico",
        "id": 1,
        "original_url": "https://blogs.nvidia.com/blog/2022/03/25/what-is-a-transformer-model/",
        "fallback": "nvidia blog: what is a transformer model?",
        "text": "transformer models apply an evolving set of mathematical techniques, called attention or self-attention, to detect subtle ways even distant data elements in a series influence and depend on each other.",
        "title": "what is a transformer model?",
        "title_link": "https://blogs.nvidia.com/blog/2022/03/25/what-is-a-transformer-model/",
        "service_name": "nvidia blog",
        "fields": [
          {
            "value": "Rick Merritt",
            "title": "Written by",
            "short": true
          },
          {
            "value": "12 minutes",
            "title": "Est. reading time",
            "short": true
          }
        ],
        "message_blocks": null
      }
    ]
  },
  {
    "client_msg_id": "8f40234a-8fa5-4b32-b756-53364ff84918",
    "type": "message",
    "text": "<https://blog.andrewcantino.com/blog/2021/04/21/prompt-engineering-tips-and-tricks/>",
    "user": "U03U1FNPEUX",
    "ts": "1663182978.056289",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "mIkT",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://blog.andrewcantino.com/blog/2021/04/21/prompt-engineering-tips-and-tricks/",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "37a12a7dbb92",
      "image_72": "https://avatars.slack-edge.com/2022-09-09/4058043481011_37a12a7dbb926b2c9c86_72.png",
      "first_name": "Jennifer",
      "real_name": "Jennifer Carrillo",
      "display_name": "Jennifer Carrillo",
      "team": "T03U4J8HMUG",
      "name": "Jennifer",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://blog.andrewcantino.com/blog/2021/04/21/prompt-engineering-tips-and-tricks/",
        "ts": 1619029800,
        "service_icon": "https://blog.andrewcantino.com/assets/apple-touch-icon.png",
        "id": 1,
        "original_url": "https://blog.andrewcantino.com/blog/2021/04/21/prompt-engineering-tips-and-tricks/",
        "fallback": "andrew makes things: prompt engineering tips and tricks with gpt-3",
        "text": "what gpt-3 prompt engineering is, why it matters, and some tips and tricks to help you do it well.",
        "title": "prompt engineering tips and tricks with gpt-3",
        "title_link": "https://blog.andrewcantino.com/blog/2021/04/21/prompt-engineering-tips-and-tricks/",
        "service_name": "andrew makes things",
        "message_blocks": null
      }
    ]
  },
  {
    "client_msg_id": "f5e2cb13-4d32-4c96-8787-b8311d37b532",
    "type": "message",
    "text": "<https://stackoverflow.com/questions/40216311/reading-in-environment-variables-from-an-environment-file>",
    "user": "U03UUR571A5",
    "ts": "1663183173.031339",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "Ibb",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://stackoverflow.com/questions/40216311/reading-in-environment-variables-from-an-environment-file",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "g95c5cde44bc",
      "image_72": "https://secure.gravatar.com/avatar/95c5cde44bc023bd369920b7e1ed0c94.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0017-72.png",
      "first_name": "Kelsey",
      "real_name": "Kelsey Shields",
      "display_name": "Kelsey Shields",
      "team": "T03U4J8HMUG",
      "name": "Kelsey",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://stackoverflow.com/questions/40216311/reading-in-environment-variables-from-an-environment-file",
        "thumb_url": "https://cdn.sstatic.net/sites/stackoverflow/img/apple-touch-icon@2.png?v=73d79a89bded",
        "thumb_width": 316,
        "thumb_height": 316,
        "service_icon": "https://cdn.sstatic.net/sites/stackoverflow/img/apple-touch-icon.png?v=c78bd457575a",
        "id": 1,
        "original_url": "https://stackoverflow.com/questions/40216311/reading-in-environment-variables-from-an-environment-file",
        "fallback": "stack overflow: reading in environment variables from an environment file",
        "text": "i'd like to run in a local environment a python script which is normally run in a docker container. the docker-compose.yml specifies an env_file which looks (partially) like the following: db_addr=",
        "title": "reading in environment variables from an environment file",
        "title_link": "https://stackoverflow.com/questions/40216311/reading-in-environment-variables-from-an-environment-file",
        "service_name": "stack overflow",
        "message_blocks": null
      }
    ]
  },
  {
    "client_msg_id": "b6daae35-64f2-43ab-82a6-a89a64b516e4",
    "type": "message",
    "text": "<https://pypi.org/project/python-dotenv/>",
    "user": "U03UUR571A5",
    "ts": "1663183507.607699",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "io5K",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://pypi.org/project/python-dotenv/",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "g95c5cde44bc",
      "image_72": "https://secure.gravatar.com/avatar/95c5cde44bc023bd369920b7e1ed0c94.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0017-72.png",
      "first_name": "Kelsey",
      "real_name": "Kelsey Shields",
      "display_name": "Kelsey Shields",
      "team": "T03U4J8HMUG",
      "name": "Kelsey",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://pypi.org/project/python-dotenv/",
        "image_url": "https://pypi.org/static/images/twitter.6fecba6f.jpg",
        "image_width": 250,
        "image_height": 250,
        "image_bytes": 6869,
        "service_icon": "https://pypi.org/static/images/favicon.6a76275d.ico",
        "id": 1,
        "original_url": "https://pypi.org/project/python-dotenv/",
        "fallback": "pypi: python-dotenv",
        "text": "read key-value pairs from a .env file and set them as environment variables",
        "title": "python-dotenv",
        "title_link": "https://pypi.org/project/python-dotenv/",
        "service_name": "pypi",
        "message_blocks": null
      }
    ]
  },
  {
    "client_msg_id": "b0c8f8c2-825e-4788-8755-fa6527dd12f6",
    "type": "message",
    "text": "<https://www.kaggle.com/code/abhishek/entity-extraction-model-using-bert-pytorch>",
    "user": "U03V5Q9N516",
    "ts": "1663217820.632869",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "WVN",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://www.kaggle.com/code/abhishek/entity-extraction-model-using-bert-pytorch",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "g164928c3a69",
      "image_72": "https://secure.gravatar.com/avatar/164928c3a69af29d42a5e90b928e2f71.jpg?s=72&d=https%3A%2F%2Fa.slack-edge.com%2Fdf10d%2Fimg%2Favatars%2Fava_0010-72.png",
      "first_name": "Steven",
      "real_name": "Steven Haas",
      "display_name": "Steven Haas",
      "team": "T03U4J8HMUG",
      "name": "Steven",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://www.kaggle.com/code/abhishek/entity-extraction-model-using-bert-pytorch",
        "thumb_url": "https://storage.Stephanieapis.com/kaggle-avatars/thumbnails/5309-kg.png",
        "thumb_width": 100,
        "thumb_height": 100,
        "service_icon": "https://www.kaggle.com/favicon.ico",
        "id": 1,
        "original_url": "https://www.kaggle.com/code/abhishek/entity-extraction-model-using-bert-pytorch",
        "fallback": "entity extraction model using bert &amp; pytorch",
        "text": "explore and run machine learning code with kaggle notebooks | using data from multiple data sources",
        "title": "entity extraction model using bert &amp; pytorch",
        "title_link": "https://www.kaggle.com/code/abhishek/entity-extraction-model-using-bert-pytorch",
        "service_name": "kaggle.com",
        "message_blocks": null
      }
    ]
  },
  {
    "client_msg_id": "8fe98d07-73f4-48b2-98bf-bf617156f13e",
    "type": "message",
    "text": "<https://www.youtube.com/watch?v=zmxvs7hd-ug&amp;ab_channel=rasa>",
    "user": "U03V61VGQG0",
    "ts": "1663217837.040519",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "vqH",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://www.youtube.com/watch?v=zmxvs7hd-ug&ab_channel=rasa",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "5e18062f5298",
      "image_72": "https://avatars.slack-edge.com/2022-08-29/3997574519670_5e18062f5298c6182ca5_72.jpg",
      "first_name": "Diane",
      "real_name": "Diane Cruz",
      "display_name": "Diane Cruz",
      "team": "T03U4J8HMUG",
      "name": "Diane",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://www.youtube.com/watch?v=zmxvs7hd-ug&amp;ab_channel=rasa",
        "thumb_url": "https://i.ytimg.com/vi/zmxvs7hd-ug/hqdefault.jpg",
        "thumb_width": 480,
        "thumb_height": 360,
        "video_html": "<iframe width=\"400\" height=\"225\" src=\"https://www.youtube.com/embed/zmxvs7hd-ug?feature=oembed&autoplay=1&iv_load_policy=3\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen title=\"nlp for developers: bert | rasa\"></iframe>",
        "video_html_width": 400,
        "video_html_height": 225,
        "service_icon": "https://a.slack-edge.com/80588/img/unfurl_icons/youtube.png",
        "id": 1,
        "original_url": "https://www.youtube.com/watch?v=zmxvs7hd-ug&amp;ab_channel=rasa",
        "fallback": "youtube video: nlp for developers: bert | rasa",
        "title": "nlp for developers: bert | rasa",
        "title_link": "https://www.youtube.com/watch?v=zmxvs7hd-ug&amp;ab_channel=rasa",
        "author_name": "rasa",
        "author_link": "https://www.youtube.com/c/rasahq",
        "service_name": "youtube",
        "service_url": "https://www.youtube.com/",
        "message_blocks": null
      }
    ]
  },
  {
    "client_msg_id": "d70e494e-7ecf-4760-ac4a-07f09c47a871",
    "type": "message",
    "text": "<https://towardsdatascience.com/transformers-89034557de14>",
    "user": "U03V61VGQG0",
    "ts": "1663217902.438639",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "q2/=a",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://towardsdatascience.com/transformers-89034557de14",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "5e18062f5298",
      "image_72": "https://avatars.slack-edge.com/2022-08-29/3997574519670_5e18062f5298c6182ca5_72.jpg",
      "first_name": "Diane",
      "real_name": "Diane Cruz",
      "display_name": "Diane Cruz",
      "team": "T03U4J8HMUG",
      "name": "Diane",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://towardsdatascience.com/transformers-89034557de14",
        "ts": 1606042906,
        "image_url": "https://miro.medium.com/max/1200/0*2yfrrpqtt8tg2iuz",
        "image_width": 445,
        "image_height": 250,
        "image_bytes": 145598,
        "service_icon": "https://miro.medium.com/fit/c/152/152/1*shhtyhace2uc3iu0igkwiq.png",
        "id": 1,
        "original_url": "https://towardsdatascience.com/transformers-89034557de14",
        "fallback": "medium: transformers",
        "text": "or as i like to call it attention on steroids. :syringe::pill:",
        "title": "transformers",
        "title_link": "https://towardsdatascience.com/transformers-89034557de14",
        "service_name": "medium",
        "fields": [
          {
            "value": "10 min read",
            "title": "Reading time",
            "short": true
          }
        ],
        "message_blocks": null
      }
    ]
  },
  {
    "client_msg_id": "75c29145-8320-4113-9e1f-efe107a411ea",
    "type": "message",
    "text": "<https://www.techtarget.com/searchenterpriseai/definition/gpt-3>",
    "user": "U03V61VGQG0",
    "ts": "1663217942.761959",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "wlnF",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://www.techtarget.com/searchenterpriseai/definition/gpt-3",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "5e18062f5298",
      "image_72": "https://avatars.slack-edge.com/2022-08-29/3997574519670_5e18062f5298c6182ca5_72.jpg",
      "first_name": "Diane",
      "real_name": "Diane Cruz",
      "display_name": "Diane Cruz",
      "team": "T03U4J8HMUG",
      "name": "Diane",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://www.techtarget.com/searchenterpriseai/definition/gpt-3",
        "image_url": "https://cdn.ttgtmedia.com/itke/images/logos/ttlogo-379x201.png",
        "image_width": 379,
        "image_height": 201,
        "image_bytes": 18052,
        "service_icon": "https://www.techtarget.com/apple-touch-icon-144x144.png",
        "id": 1,
        "original_url": "https://www.techtarget.com/searchenterpriseai/definition/gpt-3",
        "fallback": "searchenterpriseai: what is gpt-3? everything you need to know",
        "text": "learn about gpt-3, including what it can do and how it works. review examples, benefits and risks, as well as the history and future of gpt-3.",
        "title": "what is gpt-3? everything you need to know",
        "title_link": "https://www.techtarget.com/searchenterpriseai/definition/gpt-3",
        "service_name": "searchenterpriseai",
        "message_blocks": null
      }
    ]
  },
  {
    "client_msg_id": "52fbdfbc-e4da-41c9-8218-c908ee089d83",
    "type": "message",
    "text": "<https://openai.com/blog/gpt-3-apps/>",
    "user": "U03V61VGQG0",
    "ts": "1663218012.439709",
    "blocks": [
      {
        "type": "rich_text",
        "block_id": "5f=D",
        "elements": [
          {
            "type": "rich_text_section",
            "elements": [
              {
                "type": "link",
                "url": "https://openai.com/blog/gpt-3-apps/",
                "text": null
              }
            ]
          }
        ]
      }
    ],
    "team": "T03U4J8HMUG",
    "user_team": "T03U4J8HMUG",
    "source_team": "T03U4J8HMUG",
    "user_profile": {
      "avatar_hash": "5e18062f5298",
      "image_72": "https://avatars.slack-edge.com/2022-08-29/3997574519670_5e18062f5298c6182ca5_72.jpg",
      "first_name": "Diane",
      "real_name": "Diane Cruz",
      "display_name": "Diane Cruz",
      "team": "T03U4J8HMUG",
      "name": "Diane",
      "is_restricted": false,
      "is_ultra_restricted": false
    },
    "attachments": [
      {
        "from_url": "https://openai.com/blog/gpt-3-apps/",
        "ts": 1616698801,
        "image_url": "https://openai.com/content/images/2021/05/gpt-3-apps-social.png",
        "image_width": 478,
        "image_height": 250,
        "image_bytes": 619265,
        "service_icon": "https://openai.com/favicon.ico",
        "id": 1,
        "original_url": "https://openai.com/blog/gpt-3-apps/",
        "fallback": "openai: gpt-3 powers the next generation of apps",
        "text": "over 300 applications are delivering gpt-3\u2013powered search, conversation, text completion, and other advanced ai features through our api.",
        "title": "gpt-3 powers the next generation of apps",
        "title_link": "https://openai.com/blog/gpt-3-apps/",
        "service_name": "openai",
        "fields": [
          {
            "value": "OpenAI",
            "title": "Written by",
            "short": true
          },
          {
            "value": "API, Announcements",
            "title": "Filed under",
            "short": true
          }
        ],
        "message_blocks": null
      }
    ]
  }
]